{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Application \n",
    "\n",
    "Models: \n",
    "1. Naive Bayes (Gaussian & Multinominal) \n",
    "2. Logistic Regression\n",
    "3. KNN\n",
    "4. Stochastic Gradient Descent\n",
    "5. SVM (Linear, Poly, Quadratic, RBF)\n",
    "6. Decision Tree Classifier\n",
    "7. Decision Tree Bagging\n",
    "8. Decision Tree Adaboost\n",
    "9. Random Forest\n",
    "10. Vote Classification \n",
    "\n",
    "Approaches: \n",
    "\n",
    "* 70% Training and 30% Testing split \n",
    "* Cross Validation with 10 folds \n",
    "\n",
    "Metrics: \n",
    "\n",
    "* Accuracy Scores (Traing and Test)\n",
    "* Mean Accuracy Scores - Cross Validation\n",
    "* AUC Scores\n",
    "* Confusion Matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>total_bids</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>total_time</th>\n",
       "      <th>average_time</th>\n",
       "      <th>total_auction per user</th>\n",
       "      <th>mean_bids_per_auctions</th>\n",
       "      <th>mean_time_auction</th>\n",
       "      <th>total_country</th>\n",
       "      <th>number_ip</th>\n",
       "      <th>mean_ips_per_auction</th>\n",
       "      <th>number_url</th>\n",
       "      <th>number_devices</th>\n",
       "      <th>computers</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>24</td>\n",
       "      <td>9.759490e+15</td>\n",
       "      <td>9.772620e+15</td>\n",
       "      <td>2.343870e+17</td>\n",
       "      <td>9.766130e+15</td>\n",
       "      <td>18</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5.425630e+14</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>3</td>\n",
       "      <td>9.764050e+15</td>\n",
       "      <td>9.770510e+15</td>\n",
       "      <td>2.930060e+16</td>\n",
       "      <td>9.766870e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.766870e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>4</td>\n",
       "      <td>9.765400e+15</td>\n",
       "      <td>9.772540e+15</td>\n",
       "      <td>3.907760e+16</td>\n",
       "      <td>9.769390e+15</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.442350e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>155</td>\n",
       "      <td>9.759250e+15</td>\n",
       "      <td>9.771230e+15</td>\n",
       "      <td>1.513130e+18</td>\n",
       "      <td>9.762120e+15</td>\n",
       "      <td>23</td>\n",
       "      <td>6.739130</td>\n",
       "      <td>4.244400e+14</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "      <td>5.347826</td>\n",
       "      <td>91</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7eaefc97fbf6af12e930528151f86eb91bafh</td>\n",
       "      <td>1</td>\n",
       "      <td>9.761130e+15</td>\n",
       "      <td>9.761130e+15</td>\n",
       "      <td>9.761130e+15</td>\n",
       "      <td>9.761130e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.761130e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>9744d8ea513490911a671959c4a530d81fj5e</td>\n",
       "      <td>248</td>\n",
       "      <td>9.759270e+15</td>\n",
       "      <td>9.772850e+15</td>\n",
       "      <td>2.421780e+18</td>\n",
       "      <td>9.765240e+15</td>\n",
       "      <td>91</td>\n",
       "      <td>2.725275</td>\n",
       "      <td>1.073100e+14</td>\n",
       "      <td>13</td>\n",
       "      <td>92</td>\n",
       "      <td>1.010989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>2baa5a9ec317cb21a11d83f6dc72a2d6xy9jb</td>\n",
       "      <td>11</td>\n",
       "      <td>9.759280e+15</td>\n",
       "      <td>9.771590e+15</td>\n",
       "      <td>1.074190e+17</td>\n",
       "      <td>9.765370e+15</td>\n",
       "      <td>2</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.882680e+15</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>65d8228c6c1e5b6042f397afed8a5c7cbo6x3</td>\n",
       "      <td>149</td>\n",
       "      <td>9.759290e+15</td>\n",
       "      <td>9.771980e+15</td>\n",
       "      <td>1.455300e+18</td>\n",
       "      <td>9.767110e+15</td>\n",
       "      <td>64</td>\n",
       "      <td>2.328125</td>\n",
       "      <td>1.526110e+14</td>\n",
       "      <td>23</td>\n",
       "      <td>93</td>\n",
       "      <td>1.453125</td>\n",
       "      <td>97</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>2</td>\n",
       "      <td>9.762800e+15</td>\n",
       "      <td>9.772600e+15</td>\n",
       "      <td>1.953540e+16</td>\n",
       "      <td>9.767700e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.767700e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>2</td>\n",
       "      <td>9.770760e+15</td>\n",
       "      <td>9.770760e+15</td>\n",
       "      <td>1.954150e+16</td>\n",
       "      <td>9.770760e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.770760e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1416 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  total_bids      min_time  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a          24  9.759490e+15   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo           3  9.764050e+15   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj           4  9.765400e+15   \n",
       "3     4ab12bc61c82ddd9c2d65e60555808acqgos1         155  9.759250e+15   \n",
       "4     7eaefc97fbf6af12e930528151f86eb91bafh           1  9.761130e+15   \n",
       "...                                     ...         ...           ...   \n",
       "1411  9744d8ea513490911a671959c4a530d81fj5e         248  9.759270e+15   \n",
       "1412  2baa5a9ec317cb21a11d83f6dc72a2d6xy9jb          11  9.759280e+15   \n",
       "1413  65d8228c6c1e5b6042f397afed8a5c7cbo6x3         149  9.759290e+15   \n",
       "1414  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl           2  9.762800e+15   \n",
       "1415  84a769adc98498f52debfe57b93a0789556f4           2  9.770760e+15   \n",
       "\n",
       "          max_time    total_time  average_time  total_auction per user  \\\n",
       "0     9.772620e+15  2.343870e+17  9.766130e+15                      18   \n",
       "1     9.770510e+15  2.930060e+16  9.766870e+15                       1   \n",
       "2     9.772540e+15  3.907760e+16  9.769390e+15                       4   \n",
       "3     9.771230e+15  1.513130e+18  9.762120e+15                      23   \n",
       "4     9.761130e+15  9.761130e+15  9.761130e+15                       1   \n",
       "...            ...           ...           ...                     ...   \n",
       "1411  9.772850e+15  2.421780e+18  9.765240e+15                      91   \n",
       "1412  9.771590e+15  1.074190e+17  9.765370e+15                       2   \n",
       "1413  9.771980e+15  1.455300e+18  9.767110e+15                      64   \n",
       "1414  9.772600e+15  1.953540e+16  9.767700e+15                       1   \n",
       "1415  9.770760e+15  1.954150e+16  9.770760e+15                       1   \n",
       "\n",
       "      mean_bids_per_auctions  mean_time_auction  total_country  number_ip  \\\n",
       "0                   1.333333       5.425630e+14              6         20   \n",
       "1                   3.000000       9.766870e+15              1          3   \n",
       "2                   1.000000       2.442350e+15              1          4   \n",
       "3                   6.739130       4.244400e+14              2        123   \n",
       "4                   1.000000       9.761130e+15              1          1   \n",
       "...                      ...                ...            ...        ...   \n",
       "1411                2.725275       1.073100e+14             13         92   \n",
       "1412                5.500000       4.882680e+15              2         11   \n",
       "1413                2.328125       1.526110e+14             23         93   \n",
       "1414                2.000000       9.767700e+15              1          2   \n",
       "1415                2.000000       9.770760e+15              1          1   \n",
       "\n",
       "      mean_ips_per_auction  number_url  number_devices  computers  jewelry  \\\n",
       "0                 1.111111           1              14          0        0   \n",
       "1                 3.000000           2               2          0        0   \n",
       "2                 1.000000           2               2          0        0   \n",
       "3                 5.347826          91              53          0        0   \n",
       "4                 1.000000           1               1          0        0   \n",
       "...                    ...         ...             ...        ...      ...   \n",
       "1411              1.010989          80              72          0        1   \n",
       "1412              5.500000          11               7          0        0   \n",
       "1413              1.453125          97              61          0        0   \n",
       "1414              2.000000           1               2          0        0   \n",
       "1415              1.000000           1               1          0        1   \n",
       "\n",
       "      outcome  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "1411        0  \n",
       "1412        0  \n",
       "1413        0  \n",
       "1414        0  \n",
       "1415        0  \n",
       "\n",
       "[1416 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Features selected\n",
    " \n",
    "dataset = pd.read_csv(r'C:\\Users\\cinti\\Documents\\PythonF\\Final_Project_ML\\bidders_features_selected.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      total_bids      min_time      max_time    total_time  average_time  \\\n",
      "0             24  9.759490e+15  9.772620e+15  2.343870e+17  9.766130e+15   \n",
      "1              3  9.764050e+15  9.770510e+15  2.930060e+16  9.766870e+15   \n",
      "2              4  9.765400e+15  9.772540e+15  3.907760e+16  9.769390e+15   \n",
      "3            155  9.759250e+15  9.771230e+15  1.513130e+18  9.762120e+15   \n",
      "4              1  9.761130e+15  9.761130e+15  9.761130e+15  9.761130e+15   \n",
      "...          ...           ...           ...           ...           ...   \n",
      "1411         248  9.759270e+15  9.772850e+15  2.421780e+18  9.765240e+15   \n",
      "1412          11  9.759280e+15  9.771590e+15  1.074190e+17  9.765370e+15   \n",
      "1413         149  9.759290e+15  9.771980e+15  1.455300e+18  9.767110e+15   \n",
      "1414           2  9.762800e+15  9.772600e+15  1.953540e+16  9.767700e+15   \n",
      "1415           2  9.770760e+15  9.770760e+15  1.954150e+16  9.770760e+15   \n",
      "\n",
      "      total_auction per user  mean_bids_per_auctions  mean_time_auction  \\\n",
      "0                         18                1.333333       5.425630e+14   \n",
      "1                          1                3.000000       9.766870e+15   \n",
      "2                          4                1.000000       2.442350e+15   \n",
      "3                         23                6.739130       4.244400e+14   \n",
      "4                          1                1.000000       9.761130e+15   \n",
      "...                      ...                     ...                ...   \n",
      "1411                      91                2.725275       1.073100e+14   \n",
      "1412                       2                5.500000       4.882680e+15   \n",
      "1413                      64                2.328125       1.526110e+14   \n",
      "1414                       1                2.000000       9.767700e+15   \n",
      "1415                       1                2.000000       9.770760e+15   \n",
      "\n",
      "      total_country  number_ip  mean_ips_per_auction  number_url  \\\n",
      "0                 6         20              1.111111           1   \n",
      "1                 1          3              3.000000           2   \n",
      "2                 1          4              1.000000           2   \n",
      "3                 2        123              5.347826          91   \n",
      "4                 1          1              1.000000           1   \n",
      "...             ...        ...                   ...         ...   \n",
      "1411             13         92              1.010989          80   \n",
      "1412              2         11              5.500000          11   \n",
      "1413             23         93              1.453125          97   \n",
      "1414              1          2              2.000000           1   \n",
      "1415              1          1              1.000000           1   \n",
      "\n",
      "      number_devices  computers  jewelry  \n",
      "0                 14          0        0  \n",
      "1                  2          0        0  \n",
      "2                  2          0        0  \n",
      "3                 53          0        0  \n",
      "4                  1          0        0  \n",
      "...              ...        ...      ...  \n",
      "1411              72          0        1  \n",
      "1412               7          0        0  \n",
      "1413              61          0        0  \n",
      "1414               2          0        0  \n",
      "1415               1          0        1  \n",
      "\n",
      "[1416 rows x 15 columns]\n",
      "      outcome\n",
      "0           0\n",
      "1           0\n",
      "2           0\n",
      "3           0\n",
      "4           0\n",
      "...       ...\n",
      "1411        0\n",
      "1412        0\n",
      "1413        0\n",
      "1414        0\n",
      "1415        0\n",
      "\n",
      "[1416 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Features X Outcome y\n",
    "\n",
    "X = dataset.iloc[:,:-1]\n",
    "X = X.drop(columns=['bidder_id'])\n",
    "y = dataset.iloc[:,-1:]\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11384323,  0.7605989 ,  0.82520858, ..., -0.31050702,\n",
       "        -0.14203137, -0.50088261],\n",
       "       [-0.11717979,  0.83296322,  0.79376181, ..., -0.39576412,\n",
       "        -0.14203137, -0.50088261],\n",
       "       [-0.1170209 ,  0.85438686,  0.82401628, ..., -0.39576412,\n",
       "        -0.14203137, -0.50088261],\n",
       "       ...,\n",
       "       [-0.09398276,  0.75742503,  0.81567022, ...,  0.0234166 ,\n",
       "        -0.14203137, -0.50088261],\n",
       "       [-0.11733867,  0.81312651,  0.8249105 , ..., -0.39576412,\n",
       "        -0.14203137, -0.50088261],\n",
       "       [-0.11733867,  0.93944667,  0.79748773, ..., -0.40286888,\n",
       "        -0.14203137,  1.99647577]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some models need standardized values to perform better \n",
    "sc = StandardScaler()\n",
    "X_st = sc.fit_transform(X)\n",
    "X_st "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dictionary to keep the score of all models \n",
    "\n",
    "dict_scores  = {}\n",
    "dict_scores_auc  = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Naive Bayes : \n",
    "\n",
    "    Gaussian & Multinomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Bayes Gaussian\n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9247058823529412\n",
      "Accuracy score on train: 0.9434914228052472\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[393   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       393\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.46      0.50      0.48       425\n",
      "weighted avg       0.86      0.92      0.89       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.66583124 0.69005848 0.64745196 0.79699248 0.73600668 0.60233918\n",
      " 0.81766917 0.68890977 0.62121212 0.76936027]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Gaussian:  0.7035831371357687\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.93661972 0.93661972 0.93661972 0.93661972 0.93661972\n",
      " 0.94326241 0.94326241 0.93617021 0.90780142]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Gaussian:  0.9350214763759863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Gaussian:\n",
    "\n",
    "print('Gaussian Bayes Gaussian\\n')\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gnb.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(gnb.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(gnb.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(gnb, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Gaussian: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['gnb'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(gnb, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Gaussian: ', cv_score.mean())\n",
    "\n",
    "dict_scores['gnb'] = cv_score.mean() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Multinominal\n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.8705882352941177\n",
      "Accuracy score on train: 0.8678102926337034\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[360  33]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       393\n",
      "           1       0.23      0.31      0.27        32\n",
      "\n",
      "    accuracy                           0.87       425\n",
      "   macro avg       0.59      0.61      0.60       425\n",
      "weighted avg       0.89      0.87      0.88       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.51796157 0.55096074 0.59231412 0.63283208 0.46992481 0.58103592\n",
      " 0.51738722 0.63862782 0.74368687 0.66540404]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Multinominal:  0.5910135186450975\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.87323944 0.83802817 0.91549296 0.8943662  0.88028169 0.8943662\n",
      " 0.86524823 0.87234043 0.90780142 0.85815603]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Multinominal:  0.8799320747178104\n"
     ]
    }
   ],
   "source": [
    "# Multinominal:\n",
    "\n",
    "print('Naive Bayes Multinominal\\n')\n",
    "\n",
    "mnb = MultinomialNB().fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Train the model using the training sets\n",
    "mnb.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(mnb.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(mnb.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(mnb, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Multinominal: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['mnb'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(mnb, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Multinominal: ', cv_score.mean())\n",
    "\n",
    "dict_scores['mbn'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9247058823529412\n",
      "Accuracy score on train: 0.9434914228052472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confusion Matrix ===\n",
      "[[393   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       393\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.46      0.50      0.48       425\n",
      "weighted avg       0.86      0.92      0.89       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Logistic Regression:  0.5\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.93661972 0.93661972 0.93661972 0.93661972 0.93661972\n",
      " 0.94326241 0.94326241 0.93617021 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Logistic Regression:  0.9378583558086107\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "print('Logistic Regression\\n')\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(lr.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(lr.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(lr, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Logistic Regression: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['lr'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(lr, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Logistic Regression: ', cv_score.mean())\n",
    "\n",
    "dict_scores['lg'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9247058823529412\n",
      "Accuracy score on train: 0.9434914228052472\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[393   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       393\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.46      0.50      0.48       425\n",
      "weighted avg       0.86      0.92      0.89       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.68003342 0.63450292 0.60944027 0.71804511 0.78320802 0.62030075\n",
      " 0.71475564 0.91071429 0.83796296 0.77104377]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - KNN:  0.7280007151717678\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.93661972 0.93661972 0.93661972 0.93661972 0.93661972\n",
      " 0.94326241 0.94326241 0.93617021 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - KNN:  0.9378583558086107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# KNN:\n",
    "\n",
    "print('KNN\\n')\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "\n",
    "# Train the model using the training sets\n",
    "knn.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(knn.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(knn.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(knn, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - KNN: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['knn'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(knn, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - KNN: ', cv_score.mean())\n",
    "\n",
    "dict_scores['knn'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent\n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9247058823529412\n",
      "Accuracy score on train: 0.9434914228052472\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[393   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       393\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.46      0.50      0.48       425\n",
      "weighted avg       0.86      0.92      0.89       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.32080201 0.72180451 0.31161236 0.84294069 0.2406015  0.16457811\n",
      " 0.21240602 0.12593985 0.09343434 0.1952862 ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - SGD:  0.3229405584668742\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.06338028 0.93661972 0.06338028 0.93661972 0.93661972\n",
      " 0.94326241 0.94326241 0.93617021 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - SGD:  0.7632104684846668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "print('Stochastic Gradient Descent\\n')\n",
    "\n",
    "sgd = SGDClassifier(loss = 'modified_huber', shuffle = True, random_state=101)\n",
    "\n",
    "sgd.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(sgd.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(sgd.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(sgd, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - SGD: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['sgd'] = cv_score.mean() \n",
    "\n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(sgd, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - SGD: ', cv_score.mean())\n",
    "\n",
    "dict_scores['sgd'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9317647058823529\n",
      "Accuracy score on train: 0.9404641775983855\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[396   0]\n",
      " [ 29   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.47      0.50      0.48       425\n",
      "weighted avg       0.87      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.49206349 0.52213868 0.55304929 0.58061821 0.59398496 0.57811195\n",
      " 0.3787594  0.43421053 0.77861953 0.55387205]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - SVM Linear:  0.546542809042809\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.93661972 0.93661972 0.93661972 0.93661972 0.93661972\n",
      " 0.94326241 0.94326241 0.93617021 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - SVM Linear:  0.9378583558086107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM \n",
    "\n",
    "print('Linear SVM \\n')\n",
    "\n",
    "X_st_train, X_st_test, y_train, y_test = train_test_split(X_st, y, test_size=0.3)\n",
    "\n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "svm_linear.fit(X_st_train, np.ravel(y_train))\n",
    "y_pred = svm_linear.predict(X_st_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(svm_linear.score(X_st_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(svm_linear.score(X_st_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(svm_linear, X_st, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - SVM Linear: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['svm_linear'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(svm_linear, X_st, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - SVM Linear: ', cv_score.mean())\n",
    "\n",
    "dict_scores['svm_linear'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly SVM \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9317647058823529\n",
      "Accuracy score on train: 0.9475277497477296\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[395   1]\n",
      " [ 28   1]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.50      0.03      0.06        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.72      0.52      0.51       425\n",
      "weighted avg       0.90      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.63993317 0.68253968 0.73767753 0.61319967 0.55137845 0.56307435\n",
      " 0.54699248 0.65225564 0.72979798 0.69107744]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - SVM Poly:  0.6407926381610592\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.94366197 0.93661972 0.93661972 0.93661972 0.93661972\n",
      " 0.92907801 0.95035461 0.95035461 0.94326241]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - SVM Poly:  0.9399810208770353\n"
     ]
    }
   ],
   "source": [
    "# Poly\n",
    "\n",
    "print('Poly SVM \\n')\n",
    "svm_poly = svm.SVC(kernel='poly')\n",
    "svm_poly.fit(X_st_train, np.ravel(y_train))\n",
    "y_pred = svm_poly.predict(X_st_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(svm_poly.score(X_st_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(svm_poly.score(X_st_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(svm_poly, X_st, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - SVM Poly: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['svm_poly'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(svm_poly, X_st, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - SVM Poly: ', cv_score.mean())\n",
    "\n",
    "dict_scores['svm_poly'] = cv_score.mean() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic SVM \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9317647058823529\n",
      "Accuracy score on train: 0.9445005045408678\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[396   0]\n",
      " [ 29   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.47      0.50      0.48       425\n",
      "weighted avg       0.87      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.66917293 0.6716792  0.56892231 0.48120301 0.44026734 0.48203843\n",
      " 0.31954887 0.63909774 0.76851852 0.62794613]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - SVM Quadratic:  0.566839447102605\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.93661972 0.93661972 0.93661972 0.93661972 0.93661972\n",
      " 0.93617021 0.94326241 0.93617021 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - SVM Quadratic:  0.9371491359504546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Quadratic\n",
    "\n",
    "print('Quadratic SVM \\n')\n",
    "\n",
    "svm_poly = svm.SVC(kernel='poly', degree=2)\n",
    "\n",
    "svm_poly.fit(X_st_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = svm_poly.predict(X_st_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(svm_poly.score(X_st_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(svm_poly.score(X_st_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(svm_poly, X_st, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - SVM Quadratic: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['svm_quadratic'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(svm_poly, X_st, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - SVM Quadratic: ', cv_score.mean())\n",
    "\n",
    "dict_scores['svm_quadratic'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9317647058823529\n",
      "Accuracy score on train: 0.9434914228052472\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[396   0]\n",
      " [ 29   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.47      0.50      0.48       425\n",
      "weighted avg       0.87      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.83040936 0.78362573 0.73099415 0.68504595 0.6908939  0.82790309\n",
      " 0.7537594  0.70582707 0.89225589 0.79040404]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - SVM RBF:  0.7691118579276475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.93661972 0.93661972 0.93661972 0.93661972 0.93661972 0.93661972\n",
      " 0.94326241 0.94326241 0.93617021 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - SVM RBF:  0.9378583558086107\n"
     ]
    }
   ],
   "source": [
    "#RBF\n",
    "\n",
    "print('RBF SVM \\n')\n",
    "\n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "\n",
    "svm_rbf.fit(X_st_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = svm_rbf.predict(X_st_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(svm_rbf.score(X_st_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(svm_rbf.score(X_st_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(svm_rbf, X_st, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - SVM RBF: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['svm_rbf'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(svm_rbf, X_st, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - SVM RBF: ', cv_score.mean())\n",
    "\n",
    "dict_scores['svm_RBF'] = cv_score.mean() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.851764705882353\n",
      "Accuracy score on train: 0.9979818365287588\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[361  35]\n",
      " [ 28   1]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       396\n",
      "           1       0.03      0.03      0.03        29\n",
      "\n",
      "    accuracy                           0.85       425\n",
      "   macro avg       0.48      0.47      0.48       425\n",
      "weighted avg       0.87      0.85      0.86       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.64786967 0.51420217 0.70342523 0.47744361 0.58479532 0.75146199\n",
      " 0.60244361 0.59868421 0.58459596 0.57323232]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Decision Tree:  0.6038154097364624\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.92957746 0.88732394 0.93661972 0.90140845 0.88028169 0.92253521\n",
      " 0.90780142 0.92198582 0.90780142 0.89361702]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Decision Tree:  0.9088952152632105\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "print('Decision Tree Classifier \\n')\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(dt.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(dt.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(dt, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Decision Tree: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['dt'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(dt, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Decision Tree: ', cv_score.mean())\n",
    "\n",
    "dict_scores['dt'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Decision Tree Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Bagging  \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9317647058823529\n",
      "Accuracy score on train: 0.9556004036326943\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[396   0]\n",
      " [ 29   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.47      0.50      0.48       425\n",
      "weighted avg       0.87      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.87886383 0.73308271 0.76441103 0.81035923 0.74603175 0.90350877\n",
      " 0.74671053 0.83505639 0.80092593 0.8030303 ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Decision Tree Bagging:  0.8021980456190982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.94366197 0.94366197 0.92957746 0.92957746 0.92253521 0.93661972\n",
      " 0.94326241 0.94326241 0.95744681 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Decision Tree Bagging:  0.9385775646788534\n"
     ]
    }
   ],
   "source": [
    "#Bagging \n",
    "\n",
    "print('Decision Tree Bagging  \\n')\n",
    "\n",
    "# max_samples: maximum size 0.5=50% of each sample taken from the full dataset\n",
    "# max_features: maximum of features 1=100% taken here all 10K \n",
    "# n_estimators: number of decision trees \n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "\n",
    "bg.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = bg.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(bg.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(bg.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(bg, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Decision Tree Bagging: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['bg'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(bg, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Decision Tree Bagging: ', cv_score.mean())\n",
    "\n",
    "dict_scores['bg'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Decision Tree Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Adaboost \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9223529411764706\n",
      "Accuracy score on train: 0.9788092835519677\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[390   6]\n",
      " [ 27   2]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       396\n",
      "           1       0.25      0.07      0.11        29\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.59      0.53      0.53       425\n",
      "weighted avg       0.89      0.92      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.81328321 0.62865497 0.73809524 0.73433584 0.74352548 0.74603175\n",
      " 0.83928571 0.76691729 0.59259259 0.65277778]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Decision Tree Adaboost:  0.7255499860763018\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.91549296 0.92253521 0.95070423 0.9084507  0.8943662  0.94366197\n",
      " 0.92907801 0.95744681 0.92907801 0.95035461]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Decision Tree Adaboost:  0.9301168714414144\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Adaboost \n",
    "\n",
    "print('Decision Tree Adaboost \\n')\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=10,learning_rate=0.6)\n",
    "\n",
    "adb.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = adb.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(adb.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(adb.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(adb, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Decision Tree Adaboost: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['adb'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(adb, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Decision Tree Adaboost: ', cv_score.mean())\n",
    "\n",
    "dict_scores['adb'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9294117647058824\n",
      "Accuracy score on train: 0.9969727547931383\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[395   1]\n",
      " [ 29   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.47      0.50      0.48       425\n",
      "weighted avg       0.87      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.85004177 0.8091061  0.8015873  0.79573935 0.91896408 0.92021721\n",
      " 0.86090226 0.94736842 0.9212963  0.84006734]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8665290119237488\n",
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.94366197 0.94366197 0.96478873 0.92957746 0.94366197 0.95070423\n",
      " 0.94326241 0.95035461 0.94326241 0.94326241]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Random Forest:  0.9456198181999801\n"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "\n",
    "print('Random Forest \\n')\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(rf.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(rf.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(rf, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Random Forest: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['rf'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(rf, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Random Forest: ', cv_score.mean())\n",
    "\n",
    "dict_scores['rf'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classification \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9294117647058824\n",
      "Accuracy score on train: 0.9424823410696267\n"
     ]
    }
   ],
   "source": [
    "# Voting Classification \n",
    "\n",
    "print('Voting Classification \\n')\n",
    "\n",
    "vc=VotingClassifier(estimators=[('mnb',mnb),('lr',lr),('rf',rf),('svm',svm_linear)],voting='hard')\n",
    "vc.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(vc.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(vc.score(X_train, y_train)))\n",
    "\n",
    "dict_scores['vc'] = vc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gnb': 0.9350214763759863, 'mbn': 0.8799320747178104, 'lg': 0.9378583558086107, 'knn': 0.9378583558086107, 'sgd': 0.7632104684846668, 'svm_linear': 0.9378583558086107, 'svm_poly': 0.9399810208770353, 'svm_quadratic': 0.9371491359504546, 'svm_RBF': 0.9378583558086107, 'dt': 0.9088952152632105, 'bg': 0.9385775646788534, 'adb': 0.9301168714414144, 'rf': 0.9456198181999801, 'vc': 0.9294117647058824}\n"
     ]
    }
   ],
   "source": [
    "print(dict_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gnb': 0.7035831371357687, 'mnb': 0.5910135186450975, 'lr': 0.5, 'knn': 0.7280007151717678, 'sgd': 0.3229405584668742, 'svm_linear': 0.546542809042809, 'svm_poly': 0.6407926381610592, 'svm_quadratic': 0.566839447102605, 'svm_rbf': 0.7691118579276475, 'dt': 0.6038154097364624, 'bg': 0.8021980456190982, 'adb': 0.7255499860763018, 'rf': 0.8665290119237488}\n"
     ]
    }
   ],
   "source": [
    "print(dict_scores_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering both Accuracy and AUC curve, Random Forest performs best in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunning Parameters \n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  7.2min finished\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 80,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model to tune\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations, \n",
    "# and use all available cores\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9317647058823529\n",
      "Accuracy score on train: 0.9404641775983855\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[396   0]\n",
      " [ 29   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.47      0.50      0.48       425\n",
      "weighted avg       0.87      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.82038429 0.81787803 0.75898079 0.89139515 0.87969925 0.92314119\n",
      " 0.86184211 0.94736842 0.93602694 0.8543771 ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8691093263461683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.94366197 0.93661972 0.94366197 0.93661972 0.93661972 0.93661972\n",
      " 0.94326241 0.94326241 0.94326241 0.94326241]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Random Forest:  0.9406852462291481\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with best parameters \n",
    "\n",
    "print('Random Forest \\n')\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 600,\n",
    "                            min_samples_split= 10,\n",
    "                            min_samples_leaf= 4,\n",
    "                            max_features= 'sqrt',\n",
    "                            max_depth= 40,\n",
    "                            bootstrap= True)\n",
    "\n",
    "rf.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(rf.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(rf.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(rf, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Random Forest: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['rf'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(rf, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Random Forest: ', cv_score.mean())\n",
    "\n",
    "dict_scores['rf'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  5.8min finished\n",
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 2, 'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "RandomForestRegressor(max_depth=80, max_features=2, min_samples_leaf=5,\n",
      "                      min_samples_split=8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "best_grid = grid_search.best_estimator_\n",
    "print(best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "\n",
      "=== Results ====\n",
      "\n",
      "Using the 70% training, 30% test split:\n",
      "Accuracy score on test: 0.9317647058823529\n",
      "Accuracy score on train: 0.9404641775983855\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[396   0]\n",
      " [ 29   0]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       396\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.47      0.50      0.48       425\n",
      "weighted avg       0.87      0.93      0.90       425\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.83082707 0.80033417 0.77401838 0.89223058 0.8780284  0.93984962\n",
      " 0.85526316 0.93796992 0.92171717 0.81481481]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8645053289790132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cinti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All Accuracy Scores ===\n",
      "[0.94366197 0.93661972 0.93661972 0.93661972 0.93661972 0.94366197\n",
      " 0.94326241 0.94326241 0.94326241 0.93617021]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - Random Forest:  0.9399760263709919\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with best parameters \n",
    "\n",
    "print('Random Forest \\n')\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 100,\n",
    "                            min_samples_split= 12,\n",
    "                            min_samples_leaf= 4,\n",
    "                            max_features= 2,\n",
    "                            max_depth= 100,\n",
    "                            bootstrap= True)\n",
    "\n",
    "rf.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Accuracy: \n",
    "print('=== Results ====\\n')\n",
    "print('Using the 70% training, 30% test split:')\n",
    "print('Accuracy score on test: ' + str(rf.score(X_test, y_test)))\n",
    "print('Accuracy score on train: '+ str(rf.score(X_train, y_train)))\n",
    "\n",
    "# Using cross-validation:\n",
    "\n",
    "cv_score = cross_val_score(rf, X, np.ravel(y), cv=10, scoring='roc_auc')\n",
    "\n",
    "# Results AUC \n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print('=== All AUC Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean AUC Score ===')\n",
    "print('Mean AUC Score - Random Forest: ', cv_score.mean())\n",
    "\n",
    "dict_scores_auc['rf'] = cv_score.mean() \n",
    "\n",
    "# Results Accuracy \n",
    "cv_score = cross_val_score(rf, X, np.ravel(y), cv=10, scoring='accuracy')\n",
    "\n",
    "print('\\n=== All Accuracy Scores ===')\n",
    "print(cv_score)\n",
    "print('\\n')\n",
    "print('=== Mean Accuracy Score ===')\n",
    "print('Mean Accuracy Score - Random Forest: ', cv_score.mean())\n",
    "\n",
    "dict_scores['rf'] = cv_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6480 candidates, totalling 19440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 60.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 72.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 87.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4885 tasks      | elapsed: 105.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5816 tasks      | elapsed: 126.2min\n"
     ]
    }
   ],
   "source": [
    "# Tunning Parameters \n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "   \n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "best_grid = grid_search.best_estimator_\n",
    "print(best_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
